{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88763050",
   "metadata": {},
   "source": [
    "## ðŸ“š IMPORTAÃ‡ÃƒO DE BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fba6cd",
   "metadata": {},
   "source": [
    "## ðŸ” CARREGAR VARIÃVEIS DE AMBIENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4bdb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee627864",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ¤– CONFIGURAÃ‡ÃƒO OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84cb3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    organization='org-IsYPmtrkCS9KEDskoYDCzwa1',\n",
    "    project='proj_62XWXAEEerK598jeu0YOeuMp',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a38fc5",
   "metadata": {},
   "source": [
    "## ðŸ§© CONEXÃƒO COM O DATA WAREHOUSE (SNOWFLAKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef47716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_dw():\n",
    "    return create_engine(\n",
    "        f\"snowflake://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}/{os.getenv('DB_NAME')}?warehouse={os.getenv('DB_WAREHOUSE')}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e92b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_query(query):\n",
    "    conn = connect_dw()\n",
    "    with conn.connect() as sql:\n",
    "        try:\n",
    "            # Executando a consulta no DW\n",
    "            result = sql.execute(text(query))\n",
    "\n",
    "            # Pegando os nomes das colunas automaticamente\n",
    "            columns = result.keys()\n",
    "\n",
    "            # Buscando os dados\n",
    "            data = result.fetchall()\n",
    "\n",
    "            # Se a consulta retornou dados, retorna o DataFrame\n",
    "            if data:\n",
    "                df = pd.DataFrame(data, columns=columns)\n",
    "                return df\n",
    "            else:\n",
    "                return pd.DataFrame()  # Retorna um DataFrame vazio caso nÃ£o haja dados\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Se houver erro ao executar a query, ele serÃ¡ propagado\n",
    "            raise Exception(f\"Erro ao executar a query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c760c",
   "metadata": {},
   "source": [
    "## ðŸ” PEGAR O ID DO ASSISTENTE CRIADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac52a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID do assistente mais recente: asst_LKdSDm5rPMi3YykJuzi7U6GE\n"
     ]
    }
   ],
   "source": [
    "my_assistants = client.beta.assistants.list(order=\"desc\", limit=20)\n",
    "most_recent_assistant_id = my_assistants.data[0].id\n",
    "print(f\"ID do assistente mais recente: {most_recent_assistant_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67bba10",
   "metadata": {},
   "source": [
    "## ðŸ§  ENVIA A PERGUNTA PARA O ASSISTENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c90c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistente personalizado criado com ID: asst_QyjCVxiu7ARYqpZ25h0LbQ6u\n"
     ]
    }
   ],
   "source": [
    "# CriaÃ§Ã£o do assistente personalizado\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Analista de Dados da Feng\",\n",
    "    instructions=\"\"\"\n",
    "    VocÃª Ã© um assistente de dados da Feng. Responda sempre em portuguÃªs e apenas como assistente.\n",
    "Sua funÃ§Ã£o Ã© gerar queries SQL de uma linha (sem quebra) para serem executadas via Python no Snowflake.\n",
    "Sempre use o schema nas tabelas, por exemplo: BI_DIM.DIM_ASSINANTE.\n",
    "Nunca adicione explicaÃ§Ãµes, apenas retorne a query pura.\n",
    "\n",
    "Sobre a tabela BI_DIM.DIM_ASSINANTE:\n",
    "ContÃ©m todas as pessoas que jÃ¡ tiveram contrato\n",
    "\n",
    "SK_ASSINANTE: chave primÃ¡ria\n",
    "idpessoa: id no sistema\n",
    "sk_lead: id na tabela dim_lead\n",
    "chave_sales_force: id no Salesforce\n",
    "PROGRAMA: programa da assinatura (ex: SAO_PAULO, FLAMENGO, etc.)\n",
    "estado_ativacao: status como SÃ“CIO, INATIVO, LEAD etc\n",
    "tipo_programa: Esportes ou Multa\n",
    "sexo: M, F, I ou Null\n",
    "tipo_pessoa: tÃ­tulo ao aderir ao plano\n",
    "Flags: flag_aceita_newsletter, flag_socio_club, flag_cccredit (valores S ou N)\n",
    "idpessoa_responsavel: se tem responsÃ¡vel\n",
    "tenure: meses ativos seguidos\n",
    "total_meses_ativos: total de meses ativos atÃ© sair\n",
    "idnivel: referÃªncia Ã  dim_nivel\n",
    "\"\"\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# Guardando o ID do assistente criado\n",
    "custom_assistant_id = assistant.id\n",
    "print(f\"Assistente personalizado criado com ID: {custom_assistant_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566a559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realizar_consulta_assistente(prompt_usuario):\n",
    "    thread = client.beta.threads.create()\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt_usuario\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=custom_assistant_id,  # usa o assistente recÃ©m-criado\n",
    "    )\n",
    "\n",
    "    while run.status != \"completed\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    resposta = messages.data[0].content[0].text.value\n",
    "\n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24cca6",
   "metadata": {},
   "source": [
    "## ðŸ—£ï¸ CAPTURA A PERGUNTA DO USUÃRIO E FAZ A CONSULTA NO SNOWFLAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ea75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_consultas():\n",
    "    while True:\n",
    "        # Passo 1: Solicita ao usuÃ¡rio a consulta\n",
    "        prompt_usuario = input(\"\\nðŸ—£ï¸ O que vocÃª quer saber?\\nEx: 'Quantos sÃ³cios temos ?'\\n\\n> \")\n",
    "\n",
    "        if prompt_usuario.lower() == \"sair\":\n",
    "            print(\"\\nðŸšª Saindo do sistema de consultas.\")\n",
    "            break  # Encerra o loop se o usuÃ¡rio digitar 'sair'\n",
    "        \n",
    "        # Passo 2: Realiza a consulta com o assistente\n",
    "        print(f\"\\nðŸ’¬ Sua pergunta foi: {prompt_usuario}\")\n",
    "        print(\"\\nâš™ï¸ Enviando consulta ao assistente...\")\n",
    "        resposta = realizar_consulta_assistente(prompt_usuario)\n",
    "        print(f\"\\nðŸ“œ Query gerada pelo assistente:\\n{resposta}\")\n",
    "\n",
    "        # Passo 3: Executa a query recebida\n",
    "        try:\n",
    "            print(\"\\nâš™ï¸ Executando query no DW...\")\n",
    "            df_resultado = executar_query(resposta)\n",
    "            print(\"\\nâœ… Resultado:\")\n",
    "            display(df_resultado)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Erro ao executar a query:\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca210a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¬ Sua pergunta foi: \n",
      "\n",
      "âš™ï¸ Enviando consulta ao assistente...\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Message content must be non-empty.', 'type': 'invalid_request_error', 'param': 'content', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mloop_consultas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mloop_consultas\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ’¬ Sua pergunta foi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_usuario\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâš™ï¸ Enviando consulta ao assistente...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m resposta = \u001b[43mrealizar_consulta_assistente\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_usuario\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“œ Query gerada pelo assistente:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresposta\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Passo 3: Executa a query recebida\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mrealizar_consulta_assistente\u001b[39m\u001b[34m(prompt_usuario)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrealizar_consulta_assistente\u001b[39m(prompt_usuario):\n\u001b[32m      2\u001b[39m     thread = client.beta.threads.create()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrole\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_usuario\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     run = client.beta.threads.runs.create(\n\u001b[32m     10\u001b[39m         thread_id=thread.id,\n\u001b[32m     11\u001b[39m         assistant_id=custom_assistant_id,  \u001b[38;5;66;03m# usa o assistente recÃ©m-criado\u001b[39;00m\n\u001b[32m     12\u001b[39m     )\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m run.status != \u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igor.pedro\\Downloads\\Igor\\feng_copilot_2025\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\threads\\messages.py:102\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, thread_id, content, role, attachments, metadata, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a non-empty value for `thread_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    101\u001b[39m extra_headers = {\u001b[33m\"\u001b[39m\u001b[33mOpenAI-Beta\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33massistants=v2\u001b[39m\u001b[33m\"\u001b[39m, **(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/threads/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mthread_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrole\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattachments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mattachments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igor.pedro\\Downloads\\Igor\\feng_copilot_2025\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1276\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1263\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1264\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1271\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1272\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1273\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1274\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1275\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igor.pedro\\Downloads\\Igor\\feng_copilot_2025\\.venv\\Lib\\site-packages\\openai\\_base_client.py:949\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igor.pedro\\Downloads\\Igor\\feng_copilot_2025\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1057\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1054\u001b[39m         err.response.read()\n\u001b[32m   1056\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1060\u001b[39m     cast_to=cast_to,\n\u001b[32m   1061\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1065\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1066\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'Message content must be non-empty.', 'type': 'invalid_request_error', 'param': 'content', 'code': None}}"
     ]
    }
   ],
   "source": [
    "loop_consultas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
